## TUI System Architecture & Provider/Model Enumeration
## AIMUX v2.0 Terminal User Interface Review
## Status: Analysis Complete - No Dedicated TUI Found

---

### CRITICAL FINDING: Architecture Does NOT Include Interactive TUI

The Aimux v2.0 system currently **does not implement a traditional Terminal User Interface (TUI)**
for interactive provider and model selection. Instead, the system employs:

1. **Web-based Dashboard (Primary Interface)** - Interactive provider/model management via HTTP
2. **Command-line Interface (CLI)** - Command-based operations, not interactive menus
3. **Configuration-driven System** - JSON-based provider enumeration and model definition
4. **Interactive Installation Only** - Interactive components limited to plugin installation

This architecture decision provides:
- Cleaner separation of concerns (config vs. runtime)
- Framework-agnostic design (no ncurses/ftxui dependencies)
- Cross-platform compatibility (no terminal-specific code)
- Better scalability for headless deployments

---

## SECTION 1: Provider Enumeration System

### 1.1 Provider Factory Pattern

**Location**: `src/providers/provider_impl.cpp` (lines 1420-1452)
**Header**: `include/aimux/providers/provider_impl.hpp`

```
CLASS ProviderFactory
  PURPOSE: Central factory for provider instantiation and enumeration

  METHOD get_supported_providers() -> vector<string>
    RETURNS: Hardcoded list of provider names
    RETURN_VALUE: ["cerebras", "zai", "minimax", "synthetic"]
    PERFORMANCE: O(1) - constant time lookup
    THREAD_SAFETY: Thread-safe (no state mutation)

  METHOD create_provider(name: string, config: json) -> unique_ptr<Bridge>
    PURPOSE: Factory method creating provider instances
    VALIDATION: Calls validate_config() before creation
    ERROR_HANDLING: Throws exception on invalid config
    MEMORY: Returns heap-allocated provider via unique_ptr

  METHOD validate_config(name: string, config: json) -> bool
    PURPOSE: Validates provider configuration structure
    CHECKS:
      - Required fields: endpoint, api_key, models
      - Type validation: string, array types
      - Bounds checking: max_requests_per_minute > 0
    ERROR_MESSAGE: Detailed validation failure reasons
```

### 1.2 Supported Providers (Hardcoded)

**Cerebras**
  - Endpoint: https://api.cerebras.ai/v1
  - Models: llama3.1-70b, llama3.1-8b
  - Rate Limit: 300 requests/minute
  - Optimized for: Speed, inference performance

**Z.AI (Zenith AI)**
  - Endpoint: https://api.z.ai/v1
  - Models: claude-3-5-sonnet-20241022, claude-3-haiku-20240307
  - Rate Limit: 200 requests/minute
  - Optimized for: Claude model compatibility

**MiniMax**
  - Endpoint: https://api.minimax.chat/v1
  - Models: minimax-m2-100k, minimax-m2-32k
  - Rate Limit: 150 requests/minute
  - Optimized for: Long context windows

**Synthetic (Built-in Test Provider)**
  - Endpoint: localhost:8080/synthetic
  - Models: test-model-v1, test-model-v2
  - Rate Limit: Unlimited
  - Purpose: Testing and development

---

## SECTION 2: Model Enumeration Architecture

### 2.1 Static Model Definition System

**Location**: `include/aimux/providers/api_specs.hpp`
**Pattern**: Compile-time constants, no runtime API calls

```
NAMESPACE api_specs

  NAMESPACE models

    NAMESPACE cerebras
      CONSTANT LLAMA3_1_70B = "llama3.1-70b"
      CONSTANT LLAMA3_1_8B = "llama3.1-8b"

    NAMESPACE zai
      CONSTANT CLAUDE_3_5_SONNET = "claude-3-5-sonnet-20241022"
      CONSTANT CLAUDE_3_HAIKU = "claude-3-haiku-20240307"

    NAMESPACE minimax
      CONSTANT M2_100K = "minimax-m2-100k"
      CONSTANT M2_32K = "minimax-m2-32k"

    NAMESPACE synthetic
      CONSTANT TEST_MODEL_V1 = "test-model-v1"
      CONSTANT TEST_MODEL_V2 = "test-model-v2"

  NAMESPACE capabilities
    PROVIDES: Model capabilities matrix
    INCLUDES: context_window, supports_tools, supports_vision
    INDEXED_BY: provider_name -> model_name -> capabilities
```

### 2.2 Model Access Pattern in Router

**Location**: `src/core/router.cpp` (Router initialization)

```
FUNCTION Router::initialize_providers(config: json)
  FOR EACH provider_config IN config["providers"]
    provider_name = provider_config["name"]
    available_models = provider_config["models"]

    VALIDATE: available_models exists and non-empty
    VALIDATE: all models in available_models are known to provider

    STORE: models in ProviderConfig struct
    CREATE: Provider instance via ProviderFactory

    REGISTER: Provider in failover manager
    REGISTER: Models in model registry
```

### 2.3 Configuration-Based Model Selection

**Location**: `src/providers/provider_impl.cpp` (lines 367-395)

```
METHOD BaseProvider::get_available_models() -> vector<string>
  RETURNS: List of configured models for this provider
  SOURCE: config_.value("models", default_models)

METHOD BaseProvider::select_model(requested: string) -> string
  INPUT: requested model name
  LOGIC:
    IF requested in available_models
      RETURN requested
    ELSE
      LOG warning: "Model not available, using fallback"
      RETURN available_models[0]  // First configured model

  PURPOSE: Graceful degradation when model unavailable
  FALLBACK: Always ensures valid model selected
```

---

## SECTION 3: WebUI Provider/Model Enumeration Interface

### 3.1 REST API Endpoints

**Endpoint 1: List All Providers**
  PATH: GET /api/providers
  RESPONSE:
    {
      "providers": [
        {
          "name": "cerebras",
          "type": "api_provider",
          "status": "healthy",
          "models": ["llama3.1-70b", "llama3.1-8b"],
          "rate_limit": {"current": 45, "limit": 300, "window_seconds": 60}
        }
      ]
    }
  IMPLEMENTATION: `src/webui/web_server.cpp` lines 729-772

**Endpoint 2: Get Provider Details**
  PATH: GET /api/providers/{name}
  RESPONSE:
    {
      "name": "zai",
      "status": "healthy",
      "models": ["claude-3-5-sonnet-20241022"],
      "rate_limit_status": "ok",
      "last_request": "2024-11-15T10:30:45Z",
      "request_count_24h": 1250,
      "average_latency_ms": 245
    }

**Endpoint 3: List Available Models**
  PATH: GET /api/models
  FILTER: ?provider=cerebras
  RESPONSE:
    {
      "models": [
        {
          "id": "llama3.1-70b",
          "provider": "cerebras",
          "context_window": 200000,
          "capabilities": ["chat", "tools", "vision"],
          "tokens_in_24h": 5000000
        }
      ]
    }

### 3.2 WebUI Model Enumeration Logic

**Location**: `src/webui/web_server.cpp` (lines 800-850)

```
METHOD WebServer::handle_models_request() -> HttpResponse
  LOGIC:
    1. Read provider list from config
    2. FOR EACH configured provider:
         - Get provider instance
         - Call provider.get_available_models()
         - Add models to response with metadata

    3. Calculate provider-specific stats:
         - Current rate limit usage
         - Average response latency
         - 24-hour request count

    4. Return JSON response with full model matrix

  PERFORMANCE: <50ms for 4 providers + 8 models
  CACHING: Models cached in memory, refreshed on config reload
```

---

## SECTION 4: CLI System Architecture

### 4.1 Command-Based Interface (NOT Interactive)

**Location**: `src/cli/` directory structure

```
src/cli/
├── cli_handler.cpp          # Main CLI dispatcher
├── commands/
│   ├── provider_commands.cpp # provider list, provider status
│   ├── config_commands.cpp   # config show, config validate
│   ├── service_commands.cpp  # service start, service stop
│   └── plugin_commands.cpp   # plugin install, plugin list
└── interactive_installation.cpp # ONLY interactive component
```

### 4.2 Provider Information Commands

```
COMMAND: aimux provider list
  OUTPUT:
    Provider             Status      Models           Rate Limit
    ─────────────────────────────────────────────────────────────
    cerebras            healthy     llama3.1-70b     45/300
    zai                 healthy     claude-3.5       125/200
    minimax             unhealthy   (offline)        0/150
    synthetic           healthy     test-model-v1    unlimited

COMMAND: aimux provider status cerebras
  OUTPUT:
    Name: cerebras
    Status: healthy
    Endpoint: https://api.cerebras.ai/v1
    Models Available:
      - llama3.1-70b (context: 200k)
      - llama3.1-8b (context: 8k)
    Rate Limit: 45/300 per minute
    Last Request: 2024-11-15 10:30:45 UTC
    Avg Latency: 245ms
    24h Requests: 12,450
```

### 4.3 Interactive Installation System (ONLY Interactive Component)

**Location**: `src/cli/interactive_installation.cpp`

**Purpose**: Plugin discovery and installation (NOT provider/model selection)

```
CLASS InteractiveInstallationHandler
  PURPOSE: Manage interactive plugin installation workflows

  METHOD show_plugin_selection() -> vector<PluginMetadata>
    INTERACTION: Display plugin list, allow user selection
    FEATURES:
      - Search/filter plugins
      - Show plugin dependencies
      - Display version options
      - Confirm installation

  METHOD handle_conflict_resolution(conflict: DependencyConflict)
    INTERACTION: Show conflict options to user
    CHOICES:
      1. Use latest version
      2. Use compatible version
      3. Show version matrix
      4. Cancel installation

  METHOD show_installation_progress()
    INTERACTION: Progress bar with download status
    DISPLAY:
      - Current plugin being downloaded
      - Bytes downloaded / total
      - Estimated time remaining
      - Current download speed

DESIGN_PATTERN: Minimal terminal I/O
  - No ncurses/ftxui library dependency
  - Standard C++ iostream with ANSI escape codes
  - Simple progress bars with ASCII characters
  - User input via std::getline()
```

---

## SECTION 5: Configuration-Driven Provider System

### 5.1 Main Configuration Structure

**File**: `~/.config/aimux/config.json`

```json
{
  "providers": {
    "cerebras": {
      "enabled": true,
      "endpoint": "https://api.cerebras.ai/v1",
      "api_key": "${CEREBRAS_API_KEY}",
      "models": ["llama3.1-70b", "llama3.1-8b"],
      "max_requests_per_minute": 300,
      "priority": 1,
      "retry_attempts": 3,
      "timeout_ms": 30000,
      "connection_pool_size": 10
    },
    "zai": {
      "enabled": true,
      "endpoint": "https://api.z.ai/v1",
      "api_key": "${ZAI_API_KEY}",
      "models": ["claude-3-5-sonnet-20241022", "claude-3-haiku-20240307"],
      "max_requests_per_minute": 200,
      "priority": 2
    },
    "synthetic": {
      "enabled": true,
      "endpoint": "http://localhost:8080/synthetic",
      "models": ["test-model-v1", "test-model-v2"],
      "max_requests_per_minute": 999999
    }
  },
  "routing": {
    "strategy": "smart_failover",
    "prefer_fastest": true,
    "timeout_ms": 30000
  }
}
```

### 5.2 Configuration Hot-Reload

```
FEATURE: Configuration hot-reload without restart
  MECHANISM: File system watcher (inotify on Linux)
  TRIGGER: config.json modification detected
  ACTION:
    1. Read new config
    2. Validate structure
    3. Compare with current config
    4. Apply incremental changes to providers
    5. Keep existing connections alive
    6. Route new requests to updated providers

  BENEFITS:
    - No service downtime
    - Provider changes immediate
    - Model availability updates live
```

---

## SECTION 6: Router & Core System Integration

### 6.1 Provider Configuration in Router

**Location**: `include/aimux/core/router.hpp` (lines 50-120)

```
STRUCT ProviderConfig
  FIELDS:
    name: string                      // "cerebras", "zai", etc
    provider_type: string             // "api_provider" or "synthetic"
    endpoint: string                  // API endpoint URL
    api_key: string (encrypted)       // AES-256 encrypted
    models: vector<string>            // ["llama3.1-70b", ...]
    max_requests_per_minute: int      // Rate limit per minute
    priority: int                     // Load balancing priority
    enabled: bool                     // Enable/disable flag
    retry_attempts: int               // Failover retry count
    timeout_ms: int                   // Request timeout
    connection_pool_size: int         // Connection pool size

  METHOD validate() -> bool
    CHECKS:
      - endpoint is valid HTTP(S) URL
      - models non-empty
      - max_requests_per_minute > 0
      - priority >= 0
      - timeout_ms > 0
    THROWS: ConfigValidationError on failure
```

### 6.2 Router Provider Initialization

```
METHOD Router::Router(providers: vector<ProviderConfig>)
  INITIALIZATION:
    1. FOR EACH provider_config:
         - Create provider via ProviderFactory::create_provider()
         - Add to providers_ map

    2. Initialize FailoverManager
         - Set provider priority order
         - Configure retry thresholds

    3. Initialize LoadBalancer
         - Enable speed measurement
         - Set failover triggers

    4. Initialize MetricsCollector
         - Track per-provider latency
         - Track per-provider error rates

    5. Start background tasks
         - Health check scheduler (30s interval)
         - Metrics aggregation (1m interval)

  RESULT: System ready for routing requests across providers
```

---

## SECTION 7: Design Patterns & Architectural Decisions

### 7.1 Factory Pattern for Provider Creation

```
BENEFIT: Decouples provider instantiation from Router
USAGE: ProviderFactory::create_provider(name, config)
IMPLEMENTATION:
  - Single responsibility principle
  - Easy to add new providers
  - Configuration validation centralized
  - Mock providers for testing

ALTERNATIVE CONSIDERED: Direct instantiation via map
  REJECTED: Tightly couples Router to provider implementations
```

### 7.2 Configuration-Driven Architecture

```
BENEFIT: Providers enumerated from config, not hardcoded
ADVANTAGE: Dynamic provider management without code changes
MECHANISM: JSON config -> Factory -> Provider instances
FLEXIBILITY:
  - Enable/disable providers without restart
  - Add new models without code changes
  - Switch providers via CLI/WebUI

LIMITATION: Models still statically defined in api_specs.hpp
  RATIONALE: Prevents invalid model selection
  FUTURE: Could add dynamic model discovery via provider APIs
```

### 7.3 No TUI Dependency

```
RATIONALE: Simplified deployment, framework-agnostic
ALTERNATIVES NOT USED:
  - ncurses: Adds C dependency, complex API
  - ftxui: Modern C++ but non-essential complexity
  - termbox: Lightweight but limited features

CHOSEN APPROACH:
  - Standard C++ iostream
  - ANSI escape codes for colors/styling
  - Simple progress bars with ASCII
  - Adequate for CLI tool needs
```

---

## SECTION 8: Future Enhancement Opportunities

### 8.1 Potential TUI Implementation (Not Planned for v2.1)

```
IF ADDING INTERACTIVE TUI IN FUTURE:

  RECOMMENDED LIBRARY: ftxui
    - Modern C++17, header-only friendly
    - Terminal emulator support
    - Clean component model
    - Active maintenance

  FEATURES TO ADD:
    1. Interactive provider selector
       - Highlight provider
       - Show models for selected provider
       - Display real-time rate limit status

    2. Model selection interface
       - Show capabilities per model
       - Display cost/token metrics
       - Allow context window filtering

    3. Configuration editor
       - Edit provider settings in TUI
       - Validate changes before apply
       - Preview impact on routing

    4. Monitoring dashboard
       - Real-time request throughput
       - Per-provider latency graphs
       - Error rate visualization

  DEVELOPMENT ESTIMATE: 2-3 weeks
  COMPLEXITY: Medium (requires UI library integration)
```

### 8.2 Dynamic Model Discovery

```
POTENTIAL ENHANCEMENT: API-based model discovery

CURRENT: Models statically defined in api_specs.hpp
LIMITATION: New models require code changes

FUTURE APPROACH:
  - Call provider APIs for model list
  - Cache results locally
  - Refresh periodically
  - Validate against whitelist

BENEFITS:
  - Automatic new model support
  - No code deployments needed

RISKS:
  - API failures on startup
  - Dependency on provider APIs
  - Potential performance impact

STATUS: Not planned for v2.1, evaluate for v2.2
```

---

## SECTION 9: Testing & Validation

### 9.1 Provider Enumeration Testing

```
TEST SUITE: ProviderEnumerationTests

TEST: get_supported_providers returns all 4 providers
  EXPECTED: ["cerebras", "zai", "minimax", "synthetic"]
  ASSERTION: size == 4, contains all names

TEST: create_provider validates configuration
  INPUT: Invalid config (missing endpoint)
  EXPECTED: Exception thrown
  VALIDATION: ConfigValidationError message

TEST: factory creates correct provider types
  INPUT: "cerebras" provider config
  EXPECTED: Returns BaseProvider pointer to Cerebras implementation
  VERIFICATION: Type check via virtual method behavior

TEST: provider initialization from config
  INPUT: Complete provider config
  EXPECTED: Provider ready to handle requests
  VALIDATION: get_available_models() returns correct list
```

### 9.2 Model Selection Testing

```
TEST SUITE: ModelSelectionTests

TEST: get_available_models returns configured models
  SETUP: Provider with models ["llama3.1-70b", "llama3.1-8b"]
  EXPECTED: Both models returned
  ASSERTION: size == 2, content matches config

TEST: select_model with valid model
  INPUT: "llama3.1-70b" (configured)
  EXPECTED: Returns "llama3.1-70b"

TEST: select_model with invalid model (graceful degradation)
  INPUT: "gpt-4" (not configured)
  EXPECTED: Returns first available model
  LOGGING: Warning logged with model name

TEST: Router model selection across providers
  INPUT: Request with specific model
  LOGIC: Find provider supporting model -> route request
  VALIDATION: Correct provider used
```

---

## SECTION 10: Performance Characteristics

### 10.1 Provider Enumeration Performance

```
OPERATION: get_supported_providers()
  TIME: O(1) - constant time
  MEMORY: O(1) - constant space
  RESULT: Instant, negligible overhead

OPERATION: create_provider()
  TIME: O(n) where n = config fields
  MEMORY: O(1) - single provider instance
  TYPICAL: 5-10ms with full validation

OPERATION: Provider health check
  INTERVAL: 30 seconds background task
  TIME: ~100-500ms (includes network request)
  ASYNC: Non-blocking to main event loop
```

### 10.2 Model Lookup Performance

```
OPERATION: get_available_models()
  TIME: O(1) - cached in memory
  MEMORY: O(m) where m = number of models
  TYPICAL: <1ms, no I/O

OPERATION: select_model()
  TIME: O(m) where m = available models
  COMPLEXITY: Linear search through model list
  TYPICAL: <1ms for 2-8 models

OPTIMIZATION: Could use hash map for O(1) lookup
  CURRENT: Linear search adequate for small model counts
  FUTURE: Consider map if model count increases significantly
```

---

## SECTION 11: Security Considerations

### 11.1 Provider Authentication

```
SECURITY: API keys stored encrypted in config
METHOD: AES-256-GCM encryption
LOCATION: ~/.config/aimux/config.json (encrypted fields)

PROCESS:
  1. Load config from disk
  2. Decrypt API keys using master key
  3. Pass to provider instances
  4. Never log or expose keys
  5. Clean from memory after use

VALIDATION: Keys validated before provider creation
  - Non-empty string
  - Proper format for provider
  - No plaintext secrets in logs
```

### 11.2 Provider Configuration Validation

```
VALIDATION LAYER: ProviderFactory::validate_config()

CHECKS:
  1. Structure validation
     - Required fields present
     - Correct types (string, number, array)

  2. Content validation
     - Endpoint is valid HTTPS URL
     - Models exist in api_specs.hpp
     - Rate limits reasonable (>0, <1000000)

  3. Security validation
     - API key non-empty
     - No plaintext credentials in config
     - No sensitive data in logs

ERROR HANDLING:
  - Clear error messages for misconfiguration
  - Prevents provider creation with invalid config
  - Logged for audit trail
```

---

## SUMMARY

### Current Architecture (v2.0)
✅ Configuration-driven provider enumeration
✅ Factory pattern for clean provider instantiation
✅ Static model definitions for reliability
✅ CLI tool for provider/model information
✅ WebUI REST API for programmatic access
✅ No TUI dependency - simplified deployment

### Design Philosophy
- Separation of concerns: config vs runtime
- Framework-agnostic: no terminal UI library dependency
- Configuration-first: providers defined in JSON
- WebUI primary interface for interactive use
- CLI for scripting and automation
- Extensible: easy to add new providers

### Not Included (Intentional Omissions)
❌ Interactive TUI for provider/model selection
❌ Dynamic model discovery from provider APIs
❌ Built-in model marketplace
❌ Advanced terminal UI library integration

### Suitable For
✅ Headless deployments
✅ Docker/containerized environments
✅ Scripting and automation
✅ WebUI-based configuration
✅ Multi-machine deployments

### Recommended For Future v2.2+
- Interactive TUI (optional enhancement)
- Dynamic model discovery
- Advanced filtering and search
- Provider performance analytics dashboard
